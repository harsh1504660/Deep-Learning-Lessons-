{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cMMquPAiJElk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding , SimpleRNN , Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train) , (x_test,y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "x_train = pad_sequences(x_train,maxlen=100)\n",
        "x_test = pad_sequences(x_test,maxlen=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyaDAtatJlrR",
        "outputId": "4b3dc3f9-df01-41ad-fc24-61437b2dbd24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(10000,32,input_length=100),          ### embedding layer for converting words into vectors\n",
        "    SimpleRNN(5,return_sequences=True),            ### first rnn layer\n",
        "    SimpleRNN(5),                                  ### second layer of rnn , return sequence should be false at the last layer\n",
        "    Dense(1,activation='sigmoid')                  ###  dense layer\n",
        "])                                                 ### you can build deep lstms and deep grus as well with the same logic"
      ],
      "metadata": {
        "id": "yB0uLWtAKa-6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DWwN4N8LkUo",
        "outputId": "5d8167a2-814d-4f00-c00f-6040ab6aba76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 32)           320000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 100, 5)            190       \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 5)                 55        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320251 (1.22 MB)\n",
            "Trainable params: 320251 (1.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4NOkebcKLli3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,epochs=5,batch_size=32,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqLF_k5cLvpk",
        "outputId": "8e0da1ce-a869-4ac6-8289-e2e5c23e4b09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 121s 183ms/step - loss: 0.6534 - accuracy: 0.6044 - val_loss: 0.4990 - val_accuracy: 0.7778\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 92s 148ms/step - loss: 0.4206 - accuracy: 0.8177 - val_loss: 0.4212 - val_accuracy: 0.8170\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 95s 151ms/step - loss: 0.2798 - accuracy: 0.8933 - val_loss: 0.4328 - val_accuracy: 0.8068\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 91s 145ms/step - loss: 0.1990 - accuracy: 0.9325 - val_loss: 0.4677 - val_accuracy: 0.8064\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 93s 149ms/step - loss: 0.1447 - accuracy: 0.9528 - val_loss: 0.5265 - val_accuracy: 0.8008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2K-5bwakL8fH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}